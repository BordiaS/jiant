// Config modifications 

// This imports the defaults, which can be overridden below.
include "defaults.conf"
include "final.conf"

// _All_ final runs will share preproc and tasks.
exp_name = metalearn
eval_tasks = none
do_train = 1
train_for_eval = 0
do_eval = 0
allow_reuse_of_pretraining_parameters = 0

// Model settings
elmo_chars_only = 1
sent_enc = conv
d_hid = 512
pair_attn = 0
mnli_pair_attn = 0
snli_pair_attn = 0
mnli-alt_pair_attn = 0
wmt14_en_de_s2s_attention = none
dropout = 0.2

// Training settings
batch_size = 32
task_patience = 4
patience = 20
max_vals = 100
val_interval = 2000
lr = .00003
min_lr = 0.0000001
max_grad_norm = 5.0
scheduler = reduce_on_plateau

// For all generation tasks.
max_word_v_size = 20000
max_targ_word_v_size = 20000

// For MTL.
weighting_method = power_0.75
scaling_method = none

// Metalearning
metatrain = 1
sim_lr = .00001
max_sim_grad_norm = 5.0
multistep_loss = 0 // in exact meta setting
                   // add simulated losses to the final loss
multistep_scale = 1 // in exact meta setting [...]
slow_params_approx = 0
approx_term = "cos_sim"
pseudo_meta = 0 // for debugging only
                // in approx setting, don't really subtract loss
                // so should be equivalent to non-meta training
track_grad_stats = 0 // for debugging only
                     // in non-meta setting, track gradient cossim and magnitudes

write_preds = none
